{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0068b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import plotly\n",
    "import optuna\n",
    "import mlflow\n",
    "import dagshub\n",
    "import mlflow.sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f071278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43847afe",
   "metadata": {},
   "source": [
    "Note: To be able to run the above cell, make sure you have downloaded `en_core_web_sm` using the following command in your terminal inside your environment:\n",
    "```bash\n",
    "python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743e9cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as SushrutGaikwad\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as SushrutGaikwad\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"SushrutGaikwad/youtube-comments-analyzer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"SushrutGaikwad/youtube-comments-analyzer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository SushrutGaikwad/youtube-comments-analyzer initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository SushrutGaikwad/youtube-comments-analyzer initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting up DagsHub\n",
    "\n",
    "dagshub.init(repo_owner='SushrutGaikwad', repo_name='youtube-comments-analyzer', mlflow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90fce96",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898f7831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36793, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAW_DATA_PATH = \"../data/raw/Reddit_Data.csv\"\n",
    "df = pd.read_csv(RAW_DATA_PATH)\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[~(df[\"clean_comment\"].str.strip() == \"\")]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbddda6",
   "metadata": {},
   "source": [
    "# Running the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c091967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/eb66f0b362cf4a6e9e8119850de3216b', creation_time=1749135817604, experiment_id='7', last_update_time=1749135817604, lifecycle_stage='active', name='Improving LightGBM', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting experiment name\n",
    "\n",
    "mlflow.set_experiment(\"Improving LightGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd2c3c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adffaa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    -1: 2,\n",
    "    0: 0,\n",
    "    1: 1\n",
    "}\n",
    "df[\"category\"] = df[\"category\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b920a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_comment_for_feature_extraction(comment):\n",
    "    comment = comment.lower()\n",
    "    comment = comment.strip()\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d099abd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36793, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_comment\"] = df[\"clean_comment\"].apply(\n",
    "    preprocess_comment_for_feature_extraction\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "692dc30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_custom_features(text):\n",
    "    doc = nlp(text)\n",
    "    word_list = [token.text for token in doc]\n",
    "    \n",
    "    # Comment length\n",
    "    comment_length = len(text)\n",
    "    \n",
    "    # Word count\n",
    "    word_count = len(word_list)\n",
    "    \n",
    "    # Average word length\n",
    "    if word_count > 0:\n",
    "        avg_word_length = sum(len(word) for word in word_list) / word_count\n",
    "    else:\n",
    "        avg_word_length = 0\n",
    "    \n",
    "    # Unique word count\n",
    "    unique_word_count = len(set(word_list))\n",
    "    \n",
    "    # Lexical diversity\n",
    "    if word_count > 0:\n",
    "        lexical_diversity = unique_word_count / word_count\n",
    "    else:\n",
    "        lexical_diversity = 0\n",
    "    \n",
    "    # Count of POS tags\n",
    "    pos_count = len([token.pos_ for token in doc])\n",
    "    \n",
    "    # Proportion of POS tags\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    if word_count > 0:\n",
    "        pos_proportion = {\n",
    "            tag: pos_tags.count(tag) / word_count for tag in set(pos_tags)\n",
    "        }\n",
    "    else:\n",
    "        pos_proportion = {}\n",
    "    \n",
    "    return {\n",
    "        \"comment_length\": comment_length,\n",
    "        \"word_count\": word_count,\n",
    "        \"avg_word_length\": avg_word_length,\n",
    "        \"unique_word_count\": unique_word_count,\n",
    "        \"lexical_diversity\": lexical_diversity,\n",
    "        \"pos_count\": pos_count,\n",
    "        **pos_proportion  # Flattening the POS proportions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b85acdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADV</th>\n",
       "      <th>DET</th>\n",
       "      <th>AUX</th>\n",
       "      <th>...</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>X</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>SYM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>39</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>34</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>39</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1268</td>\n",
       "      <td>196</td>\n",
       "      <td>5.474490</td>\n",
       "      <td>136</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>196</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.025510</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219388</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459</td>\n",
       "      <td>86</td>\n",
       "      <td>4.348837</td>\n",
       "      <td>67</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>86</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>0.104651</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167</td>\n",
       "      <td>29</td>\n",
       "      <td>4.793103</td>\n",
       "      <td>24</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>29</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>690</td>\n",
       "      <td>112</td>\n",
       "      <td>5.169643</td>\n",
       "      <td>82</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>112</td>\n",
       "      <td>0.223214</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_length  word_count  avg_word_length  unique_word_count  \\\n",
       "0             259          39         5.666667                 34   \n",
       "1            1268         196         5.474490                136   \n",
       "2             459          86         4.348837                 67   \n",
       "3             167          29         4.793103                 24   \n",
       "4             690         112         5.169643                 82   \n",
       "\n",
       "   lexical_diversity  pos_count      VERB       ADV       DET       AUX  ...  \\\n",
       "0           0.871795         39  0.179487  0.076923  0.102564  0.076923  ...   \n",
       "1           0.693878        196  0.214286  0.112245  0.025510  0.051020  ...   \n",
       "2           0.779070         86  0.174419  0.104651  0.069767  0.023256  ...   \n",
       "3           0.827586         29  0.137931  0.034483  0.103448  0.068966  ...   \n",
       "4           0.732143        112  0.223214  0.062500  0.035714  0.089286  ...   \n",
       "\n",
       "       NOUN     PROPN       NUM      INTJ     SCONJ      PART   X  PUNCT  \\\n",
       "0  0.333333  0.025641       NaN       NaN       NaN       NaN NaN    NaN   \n",
       "1  0.219388  0.081633  0.005102  0.005102  0.035714       NaN NaN    NaN   \n",
       "2  0.186047  0.046512  0.011628       NaN  0.034884       NaN NaN    NaN   \n",
       "3  0.275862       NaN       NaN       NaN       NaN  0.034483 NaN    NaN   \n",
       "4  0.142857  0.044643       NaN       NaN  0.026786  0.008929 NaN    NaN   \n",
       "\n",
       "   SPACE  SYM  \n",
       "0    NaN  NaN  \n",
       "1    NaN  NaN  \n",
       "2    NaN  NaN  \n",
       "3    NaN  NaN  \n",
       "4    NaN  NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_features = pd.DataFrame([\n",
    "    extract_custom_features(comment) for comment in df[\"clean_comment\"]\n",
    "])\n",
    "custom_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd08fb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_length           0\n",
       "word_count               0\n",
       "avg_word_length          0\n",
       "unique_word_count        0\n",
       "lexical_diversity        0\n",
       "pos_count                0\n",
       "VERB                  6130\n",
       "ADV                  16269\n",
       "DET                  15488\n",
       "AUX                  16988\n",
       "CCONJ                22872\n",
       "ADP                  18132\n",
       "PRON                 15286\n",
       "ADJ                  11863\n",
       "NOUN                  3587\n",
       "PROPN                16363\n",
       "NUM                  30660\n",
       "INTJ                 33212\n",
       "SCONJ                24252\n",
       "PART                 30277\n",
       "X                    35674\n",
       "PUNCT                35397\n",
       "SPACE                36469\n",
       "SYM                  36769\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3377c604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_length       0\n",
       "word_count           0\n",
       "avg_word_length      0\n",
       "unique_word_count    0\n",
       "lexical_diversity    0\n",
       "pos_count            0\n",
       "VERB                 0\n",
       "ADV                  0\n",
       "DET                  0\n",
       "AUX                  0\n",
       "CCONJ                0\n",
       "ADP                  0\n",
       "PRON                 0\n",
       "ADJ                  0\n",
       "NOUN                 0\n",
       "PROPN                0\n",
       "NUM                  0\n",
       "INTJ                 0\n",
       "SCONJ                0\n",
       "PART                 0\n",
       "X                    0\n",
       "PUNCT                0\n",
       "SPACE                0\n",
       "SYM                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_features.fillna(0, inplace=True)\n",
    "custom_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b14bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36793, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a715456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36793, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df.reset_index(drop=True), custom_features.reset_index(drop=True)], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7131bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[~(df[\"clean_comment\"].str.strip() == \"\")]\n",
    "\n",
    "stop_words_to_include = {\"not\", \"but\", \"however\", \"no\", \"yet\"}\n",
    "\n",
    "def preprocess_comment(comment):\n",
    "    \"\"\"\n",
    "    This function performs the following tasks on a comment:\n",
    "        1) Converts the comment to lowercase,\n",
    "        2) Strips the trailing and leading whitespaces,\n",
    "        3) Removes newline characters,\n",
    "        4) Removes non-alphanumeric characters except punctuations,\n",
    "        5) Removes stopwords except a few important ones for sentiment analysis,\n",
    "        6) Lemmatizes the comment.\n",
    "    \"\"\"\n",
    "    comment = comment.lower()\n",
    "    comment = comment.strip()\n",
    "    comment = re.sub(r\"\\n\", \" \", comment)\n",
    "    comment = re.sub(r\"[^A-Za-z0-9\\s!?.,]\", \"\", comment)\n",
    "    stop_words = set(stopwords.words(\"english\")) - stop_words_to_include\n",
    "    comment = \" \".join(\n",
    "        [word for word in comment.split() if word not in stop_words]\n",
    "    )\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    comment = \" \".join(\n",
    "        [lemmatizer.lemmatize(word) for word in comment.split()]\n",
    "    )\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38cced17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36607, 26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_comment\"] = df[\"clean_comment\"].apply(preprocess_comment)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57319eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_comment', 'category', 'comment_length', 'word_count',\n",
       "       'avg_word_length', 'unique_word_count', 'lexical_diversity',\n",
       "       'pos_count', 'VERB', 'ADV', 'DET', 'AUX', 'CCONJ', 'ADP', 'PRON', 'ADJ',\n",
       "       'NOUN', 'PROPN', 'NUM', 'INTJ', 'SCONJ', 'PART', 'X', 'PUNCT', 'SPACE',\n",
       "       'SYM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d96b3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df[\"category\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5f689ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29285, 26), (7322, 26))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b2f02af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_comment', 'category', 'comment_length', 'word_count',\n",
       "       'avg_word_length', 'unique_word_count', 'lexical_diversity',\n",
       "       'pos_count', 'VERB', 'ADV', 'DET', 'AUX', 'CCONJ', 'ADP', 'PRON', 'ADJ',\n",
       "       'NOUN', 'PROPN', 'NUM', 'INTJ', 'SCONJ', 'PART', 'X', 'PUNCT', 'SPACE',\n",
       "       'SYM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "481a6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"clean_comment\"]\n",
    "y_train = train_df[\"category\"]\n",
    "\n",
    "X_test = test_df[\"clean_comment\"]\n",
    "y_test = test_df[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70b76cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1, 2)\n",
    "max_features = 1000\n",
    "vectorizer = CountVectorizer(\n",
    "    ngram_range=ngram_range,\n",
    "    max_features=max_features\n",
    ")\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4823b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized_df = pd.DataFrame(\n",
    "    X_train_vectorized.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "X_test_vectorized_df = pd.DataFrame(\n",
    "    X_test_vectorized.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd1d27b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29285, 1000), (7322, 1000))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_df.shape, X_test_vectorized_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c6535ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = pd.concat(\n",
    "    [\n",
    "        X_train_vectorized_df.reset_index(drop=True),\n",
    "        train_df.drop(columns=[\"clean_comment\", \"category\"]).reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "X_test_combined = pd.concat(\n",
    "    [\n",
    "        X_test_vectorized_df.reset_index(drop=True),\n",
    "        test_df.drop(columns=[\"clean_comment\", \"category\"]).reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd16e2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29285, 1024), (7322, 1024))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined.shape, X_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04f5f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_combined, y_train = rus.fit_resample(\n",
    "    X_train_combined,\n",
    "    y_train\n",
    ")\n",
    "\n",
    "X_train_combined = X_train_combined.astype(np.float32)\n",
    "X_test_combined = X_test_combined.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e02e66af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19758, 1024), (7322, 1024))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined.shape, X_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bff62132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters to be tuned\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": 3,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1e-1),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 30),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        # \"is_unbalance\": True,\n",
    "        # \"class_weight\": \"balanced\",\n",
    "    }\n",
    "\n",
    "    # Initialize the LightGBM model with suggested parameters\n",
    "    model = LGBMClassifier(**params, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Perform cross-validation to evaluate the model performance\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_train_combined,\n",
    "        y_train,\n",
    "        cv=3,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Return the mean accuracy score across folds\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fd464f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 12:11:07,505] A new study created in memory with name: no-name-bf4397fb-f475-4138-bd7d-69d42e33083b\n",
      "[I 2025-06-07 12:11:16,007] Trial 0 finished with value: 0.6718797449134527 and parameters: {'learning_rate': 0.03680924831843726, 'min_child_samples': 149, 'max_depth': 13, 'n_estimators': 383}. Best is trial 0 with value: 0.6718797449134527.\n",
      "[I 2025-06-07 12:11:26,854] Trial 1 finished with value: 0.761716772952728 and parameters: {'learning_rate': 0.08410481947899216, 'min_child_samples': 41, 'max_depth': 14, 'n_estimators': 365}. Best is trial 1 with value: 0.761716772952728.\n",
      "[I 2025-06-07 12:11:37,655] Trial 2 finished with value: 0.64799068731653 and parameters: {'learning_rate': 0.03908200506114505, 'min_child_samples': 197, 'max_depth': 14, 'n_estimators': 473}. Best is trial 1 with value: 0.761716772952728.\n",
      "[I 2025-06-07 12:11:43,868] Trial 3 finished with value: 0.7106994635084524 and parameters: {'learning_rate': 0.04257188022073709, 'min_child_samples': 102, 'max_depth': 11, 'n_estimators': 256}. Best is trial 1 with value: 0.761716772952728.\n",
      "[I 2025-06-07 12:11:52,880] Trial 4 finished with value: 0.6732968923980159 and parameters: {'learning_rate': 0.04836266773457451, 'min_child_samples': 148, 'max_depth': 23, 'n_estimators': 315}. Best is trial 1 with value: 0.761716772952728.\n",
      "[I 2025-06-07 12:11:56,835] Trial 5 finished with value: 0.763640044538921 and parameters: {'learning_rate': 0.07737027418171319, 'min_child_samples': 17, 'max_depth': 17, 'n_estimators': 68}. Best is trial 5 with value: 0.763640044538921.\n",
      "[I 2025-06-07 12:12:02,560] Trial 6 finished with value: 0.7261868610183217 and parameters: {'learning_rate': 0.027500951834608604, 'min_child_samples': 10, 'max_depth': 7, 'n_estimators': 149}. Best is trial 5 with value: 0.763640044538921.\n",
      "[I 2025-06-07 12:12:05,597] Trial 7 finished with value: 0.7071059823868812 and parameters: {'learning_rate': 0.09284802893402291, 'min_child_samples': 104, 'max_depth': 3, 'n_estimators': 324}. Best is trial 5 with value: 0.763640044538921.\n",
      "[I 2025-06-07 12:12:15,991] Trial 8 finished with value: 0.7194047980564835 and parameters: {'learning_rate': 0.03544751753780393, 'min_child_samples': 93, 'max_depth': 21, 'n_estimators': 416}. Best is trial 5 with value: 0.763640044538921.\n",
      "[I 2025-06-07 12:12:20,890] Trial 9 finished with value: 0.649913958902723 and parameters: {'learning_rate': 0.04944954542393413, 'min_child_samples': 192, 'max_depth': 27, 'n_estimators': 177}. Best is trial 5 with value: 0.763640044538921.\n",
      "[I 2025-06-07 12:12:23,972] Trial 10 finished with value: 0.639082903127847 and parameters: {'learning_rate': 0.0016695316268499835, 'min_child_samples': 61, 'max_depth': 30, 'n_estimators': 67}. Best is trial 5 with value: 0.763640044538921.\n",
      "[I 2025-06-07 12:12:31,010] Trial 11 finished with value: 0.7769004960016196 and parameters: {'learning_rate': 0.0859925742432705, 'min_child_samples': 14, 'max_depth': 18, 'n_estimators': 214}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:12:33,660] Trial 12 finished with value: 0.7564024698856159 and parameters: {'learning_rate': 0.07249331928391016, 'min_child_samples': 13, 'max_depth': 19, 'n_estimators': 53}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:12:40,313] Trial 13 finished with value: 0.7556938961433345 and parameters: {'learning_rate': 0.06854491924623893, 'min_child_samples': 52, 'max_depth': 18, 'n_estimators': 184}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:12:45,333] Trial 14 finished with value: 0.7747241623646118 and parameters: {'learning_rate': 0.07023669836205747, 'min_child_samples': 27, 'max_depth': 24, 'n_estimators': 124}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:12:53,641] Trial 15 finished with value: 0.7324627998785301 and parameters: {'learning_rate': 0.09887838543962194, 'min_child_samples': 77, 'max_depth': 24, 'n_estimators': 242}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:12:58,532] Trial 16 finished with value: 0.7716874177548334 and parameters: {'learning_rate': 0.06449241838529586, 'min_child_samples': 35, 'max_depth': 26, 'n_estimators': 128}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:13:03,010] Trial 17 finished with value: 0.7391436380200425 and parameters: {'learning_rate': 0.0593297239096907, 'min_child_samples': 72, 'max_depth': 30, 'n_estimators': 119}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:13:08,698] Trial 18 finished with value: 0.682356513817188 and parameters: {'learning_rate': 0.08560386228816555, 'min_child_samples': 133, 'max_depth': 21, 'n_estimators': 205}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:13:13,989] Trial 19 finished with value: 0.7668286263791882 and parameters: {'learning_rate': 0.05747316719550644, 'min_child_samples': 32, 'max_depth': 8, 'n_estimators': 216}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:13:17,693] Trial 20 finished with value: 0.6901508249822856 and parameters: {'learning_rate': 0.08097187815041952, 'min_child_samples': 122, 'max_depth': 26, 'n_estimators': 110}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:13:22,742] Trial 21 finished with value: 0.7704727199109221 and parameters: {'learning_rate': 0.06282898480261902, 'min_child_samples': 33, 'max_depth': 26, 'n_estimators': 130}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:13:28,851] Trial 22 finished with value: 0.7734588521105374 and parameters: {'learning_rate': 0.06743948998951008, 'min_child_samples': 30, 'max_depth': 23, 'n_estimators': 169}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:13:37,527] Trial 23 finished with value: 0.7558457333738232 and parameters: {'learning_rate': 0.09231100519973316, 'min_child_samples': 48, 'max_depth': 21, 'n_estimators': 285}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:13:44,980] Trial 24 finished with value: 0.7760906974390119 and parameters: {'learning_rate': 0.07512945315167416, 'min_child_samples': 25, 'max_depth': 23, 'n_estimators': 219}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:13:51,934] Trial 25 finished with value: 0.7449134527786213 and parameters: {'learning_rate': 0.07647478333533103, 'min_child_samples': 64, 'max_depth': 19, 'n_estimators': 224}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:14:01,574] Trial 26 finished with value: 0.7741168134426561 and parameters: {'learning_rate': 0.08803057984672774, 'min_child_samples': 19, 'max_depth': 15, 'n_estimators': 302}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:14:10,059] Trial 27 finished with value: 0.7525559267132301 and parameters: {'learning_rate': 0.0759824496839011, 'min_child_samples': 53, 'max_depth': 28, 'n_estimators': 265}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:14:13,383] Trial 28 finished with value: 0.7281101326045146 and parameters: {'learning_rate': 0.09987621043230753, 'min_child_samples': 83, 'max_depth': 22, 'n_estimators': 95}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:14:24,284] Trial 29 finished with value: 0.7745723251341229 and parameters: {'learning_rate': 0.056305183274762444, 'min_child_samples': 24, 'max_depth': 16, 'n_estimators': 354}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:14:31,139] Trial 30 finished with value: 0.7086243546917705 and parameters: {'learning_rate': 0.012711176379786367, 'min_child_samples': 46, 'max_depth': 12, 'n_estimators': 197}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:14:42,681] Trial 31 finished with value: 0.7745723251341229 and parameters: {'learning_rate': 0.05393120983777899, 'min_child_samples': 23, 'max_depth': 16, 'n_estimators': 352}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:14:54,840] Trial 32 finished with value: 0.7718898673954854 and parameters: {'learning_rate': 0.07190391848389159, 'min_child_samples': 23, 'max_depth': 19, 'n_estimators': 368}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:15:08,136] Trial 33 finished with value: 0.7590849276242535 and parameters: {'learning_rate': 0.08150034818247338, 'min_child_samples': 41, 'max_depth': 24, 'n_estimators': 443}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:15:20,784] Trial 34 finished with value: 0.7746735499544489 and parameters: {'learning_rate': 0.06095301596520246, 'min_child_samples': 11, 'max_depth': 13, 'n_estimators': 404}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:15:35,833] Trial 35 finished with value: 0.767081688430003 and parameters: {'learning_rate': 0.0888676881162016, 'min_child_samples': 11, 'max_depth': 13, 'n_estimators': 490}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:15:42,717] Trial 36 finished with value: 0.6533049903836421 and parameters: {'learning_rate': 0.04500233433532573, 'min_child_samples': 177, 'max_depth': 10, 'n_estimators': 403}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:15:50,071] Trial 37 finished with value: 0.7667274015588622 and parameters: {'learning_rate': 0.06265903938348058, 'min_child_samples': 40, 'max_depth': 14, 'n_estimators': 241}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:15:54,040] Trial 38 finished with value: 0.7457738637513919 and parameters: {'learning_rate': 0.07170632810968344, 'min_child_samples': 59, 'max_depth': 9, 'n_estimators': 162}. Best is trial 11 with value: 0.7769004960016196.\n",
      "[I 2025-06-07 12:16:03,662] Trial 39 finished with value: 0.7778115193845531 and parameters: {'learning_rate': 0.036538657913055286, 'min_child_samples': 11, 'max_depth': 17, 'n_estimators': 276}. Best is trial 39 with value: 0.7778115193845531.\n",
      "[I 2025-06-07 12:16:13,352] Trial 40 finished with value: 0.7714343557040187 and parameters: {'learning_rate': 0.028850678893097965, 'min_child_samples': 25, 'max_depth': 17, 'n_estimators': 290}. Best is trial 39 with value: 0.7778115193845531.\n",
      "[I 2025-06-07 12:16:19,087] Trial 41 finished with value: 0.7542767486587713 and parameters: {'learning_rate': 0.032981703842023216, 'min_child_samples': 11, 'max_depth': 12, 'n_estimators': 149}. Best is trial 39 with value: 0.7778115193845531.\n",
      "[I 2025-06-07 12:16:30,157] Trial 42 finished with value: 0.76890373519587 and parameters: {'learning_rate': 0.021391913608748016, 'min_child_samples': 20, 'max_depth': 15, 'n_estimators': 328}. Best is trial 39 with value: 0.7778115193845531.\n",
      "[I 2025-06-07 12:16:38,289] Trial 43 finished with value: 0.7657151533556027 and parameters: {'learning_rate': 0.03936654727796602, 'min_child_samples': 10, 'max_depth': 5, 'n_estimators': 442}. Best is trial 39 with value: 0.7778115193845531.\n",
      "[I 2025-06-07 12:16:47,185] Trial 44 finished with value: 0.7684988359145662 and parameters: {'learning_rate': 0.04906373016051554, 'min_child_samples': 39, 'max_depth': 20, 'n_estimators': 250}. Best is trial 39 with value: 0.7778115193845531.\n",
      "[I 2025-06-07 12:16:51,154] Trial 45 finished with value: 0.7691567972466848 and parameters: {'learning_rate': 0.08165951260483818, 'min_child_samples': 29, 'max_depth': 18, 'n_estimators': 88}. Best is trial 39 with value: 0.7778115193845531.\n",
      "[I 2025-06-07 12:16:58,679] Trial 46 finished with value: 0.7803421398927016 and parameters: {'learning_rate': 0.04094661057056505, 'min_child_samples': 17, 'max_depth': 24, 'n_estimators': 234}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:17:05,643] Trial 47 finished with value: 0.660643789857273 and parameters: {'learning_rate': 0.044699128673374396, 'min_child_samples': 158, 'max_depth': 28, 'n_estimators': 231}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:17:13,747] Trial 48 finished with value: 0.6979451361473833 and parameters: {'learning_rate': 0.0221626176608056, 'min_child_samples': 116, 'max_depth': 24, 'n_estimators': 276}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:17:20,952] Trial 49 finished with value: 0.76004656341735 and parameters: {'learning_rate': 0.03951416275483742, 'min_child_samples': 46, 'max_depth': 22, 'n_estimators': 192}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:17:29,682] Trial 50 finished with value: 0.7782164186658568 and parameters: {'learning_rate': 0.05257558823095851, 'min_child_samples': 20, 'max_depth': 23, 'n_estimators': 260}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:17:38,547] Trial 51 finished with value: 0.7791274420487904 and parameters: {'learning_rate': 0.05193593964900644, 'min_child_samples': 18, 'max_depth': 23, 'n_estimators': 268}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:17:48,271] Trial 52 finished with value: 0.7790768296386273 and parameters: {'learning_rate': 0.03625130169436809, 'min_child_samples': 18, 'max_depth': 25, 'n_estimators': 263}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:17:59,389] Trial 53 finished with value: 0.7799878530215608 and parameters: {'learning_rate': 0.03351641227151905, 'min_child_samples': 18, 'max_depth': 25, 'n_estimators': 309}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:18:09,692] Trial 54 finished with value: 0.779582953740257 and parameters: {'learning_rate': 0.0336455209871569, 'min_child_samples': 18, 'max_depth': 25, 'n_estimators': 314}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:18:20,641] Trial 55 finished with value: 0.7701184330397814 and parameters: {'learning_rate': 0.032833836064676644, 'min_child_samples': 36, 'max_depth': 25, 'n_estimators': 316}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:18:31,139] Trial 56 finished with value: 0.7775584573337383 and parameters: {'learning_rate': 0.05233846365576114, 'min_child_samples': 21, 'max_depth': 28, 'n_estimators': 297}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:18:42,186] Trial 57 finished with value: 0.7722947666767892 and parameters: {'learning_rate': 0.04321750623285562, 'min_child_samples': 32, 'max_depth': 27, 'n_estimators': 332}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:18:51,377] Trial 58 finished with value: 0.777862131794716 and parameters: {'learning_rate': 0.02992476163998891, 'min_child_samples': 18, 'max_depth': 25, 'n_estimators': 256}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:19:00,508] Trial 59 finished with value: 0.7177852009312683 and parameters: {'learning_rate': 0.023440317396783303, 'min_child_samples': 94, 'max_depth': 29, 'n_estimators': 310}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:19:09,696] Trial 60 finished with value: 0.7503795930762224 and parameters: {'learning_rate': 0.025190772345971654, 'min_child_samples': 56, 'max_depth': 25, 'n_estimators': 262}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:19:18,824] Trial 61 finished with value: 0.7776596821540642 and parameters: {'learning_rate': 0.0297204085178433, 'min_child_samples': 17, 'max_depth': 25, 'n_estimators': 259}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:19:30,828] Trial 62 finished with value: 0.7694098592974998 and parameters: {'learning_rate': 0.015984434536833965, 'min_child_samples': 16, 'max_depth': 22, 'n_estimators': 342}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:19:38,622] Trial 63 finished with value: 0.774420487903634 and parameters: {'learning_rate': 0.047184661563915896, 'min_child_samples': 29, 'max_depth': 27, 'n_estimators': 237}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:19:48,604] Trial 64 finished with value: 0.7800890778418869 and parameters: {'learning_rate': 0.04144230494365999, 'min_child_samples': 17, 'max_depth': 26, 'n_estimators': 281}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:19:58,170] Trial 65 finished with value: 0.7718392549853225 and parameters: {'learning_rate': 0.04044418921984462, 'min_child_samples': 36, 'max_depth': 23, 'n_estimators': 283}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:20:07,926] Trial 66 finished with value: 0.7414211964773764 and parameters: {'learning_rate': 0.035725694828054586, 'min_child_samples': 69, 'max_depth': 26, 'n_estimators': 305}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:20:19,524] Trial 67 finished with value: 0.7608057495697945 and parameters: {'learning_rate': 0.05302617877971135, 'min_child_samples': 44, 'max_depth': 27, 'n_estimators': 373}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:20:27,239] Trial 68 finished with value: 0.7686506731450552 and parameters: {'learning_rate': 0.03294003413423799, 'min_child_samples': 32, 'max_depth': 21, 'n_estimators': 210}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:20:35,699] Trial 69 finished with value: 0.75630124506529 and parameters: {'learning_rate': 0.04647516605509595, 'min_child_samples': 51, 'max_depth': 23, 'n_estimators': 272}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:20:45,977] Trial 70 finished with value: 0.7769511084117826 and parameters: {'learning_rate': 0.04122015166007251, 'min_child_samples': 25, 'max_depth': 29, 'n_estimators': 318}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:20:54,863] Trial 71 finished with value: 0.7768498835914567 and parameters: {'learning_rate': 0.0307183822761009, 'min_child_samples': 17, 'max_depth': 25, 'n_estimators': 250}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:21:03,904] Trial 72 finished with value: 0.7750278368255897 and parameters: {'learning_rate': 0.027016068165657856, 'min_child_samples': 17, 'max_depth': 24, 'n_estimators': 254}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:21:13,766] Trial 73 finished with value: 0.7785200931268347 and parameters: {'learning_rate': 0.05040597135514865, 'min_child_samples': 19, 'max_depth': 26, 'n_estimators': 295}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:21:23,573] Trial 74 finished with value: 0.7749266120052637 and parameters: {'learning_rate': 0.05046546853993772, 'min_child_samples': 28, 'max_depth': 26, 'n_estimators': 290}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:21:34,706] Trial 75 finished with value: 0.7753821236967303 and parameters: {'learning_rate': 0.05635978528673252, 'min_child_samples': 22, 'max_depth': 22, 'n_estimators': 340}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:21:45,036] Trial 76 finished with value: 0.770877619192226 and parameters: {'learning_rate': 0.03735170284779441, 'min_child_samples': 37, 'max_depth': 24, 'n_estimators': 298}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:21:53,515] Trial 77 finished with value: 0.779886628201235 and parameters: {'learning_rate': 0.04414875005166056, 'min_child_samples': 16, 'max_depth': 27, 'n_estimators': 232}. Best is trial 46 with value: 0.7803421398927016.\n",
      "[I 2025-06-07 12:22:01,123] Trial 78 finished with value: 0.7808482639943314 and parameters: {'learning_rate': 0.04367431615357412, 'min_child_samples': 14, 'max_depth': 29, 'n_estimators': 226}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:22:08,220] Trial 79 finished with value: 0.7752302864662415 and parameters: {'learning_rate': 0.03464842120157645, 'min_child_samples': 10, 'max_depth': 30, 'n_estimators': 184}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:22:16,626] Trial 80 finished with value: 0.7755845733373823 and parameters: {'learning_rate': 0.04267671127162219, 'min_child_samples': 27, 'max_depth': 29, 'n_estimators': 229}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:22:24,690] Trial 81 finished with value: 0.7796841785605831 and parameters: {'learning_rate': 0.04794155509147226, 'min_child_samples': 17, 'max_depth': 28, 'n_estimators': 220}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:22:32,407] Trial 82 finished with value: 0.7777102945642271 and parameters: {'learning_rate': 0.03810394855962457, 'min_child_samples': 15, 'max_depth': 28, 'n_estimators': 207}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:22:40,920] Trial 83 finished with value: 0.7802409150723758 and parameters: {'learning_rate': 0.04564423637591793, 'min_child_samples': 14, 'max_depth': 27, 'n_estimators': 220}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:22:48,431] Trial 84 finished with value: 0.7789756048183015 and parameters: {'learning_rate': 0.04636555026914311, 'min_child_samples': 13, 'max_depth': 27, 'n_estimators': 197}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:22:56,516] Trial 85 finished with value: 0.7731551776495597 and parameters: {'learning_rate': 0.04338543429475124, 'min_child_samples': 33, 'max_depth': 29, 'n_estimators': 216}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:23:04,809] Trial 86 finished with value: 0.7770017208219455 and parameters: {'learning_rate': 0.058114252554650886, 'min_child_samples': 25, 'max_depth': 30, 'n_estimators': 228}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:23:11,819] Trial 87 finished with value: 0.6469278267031076 and parameters: {'learning_rate': 0.047549874071782294, 'min_child_samples': 199, 'max_depth': 27, 'n_estimators': 243}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:23:18,481] Trial 88 finished with value: 0.7646016803320174 and parameters: {'learning_rate': 0.04083841303357499, 'min_child_samples': 42, 'max_depth': 28, 'n_estimators': 177}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:23:27,971] Trial 89 finished with value: 0.7806964267638424 and parameters: {'learning_rate': 0.05540427104849806, 'min_child_samples': 14, 'max_depth': 26, 'n_estimators': 274}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:23:34,170] Trial 90 finished with value: 0.7778115193845531 and parameters: {'learning_rate': 0.044624648987696386, 'min_child_samples': 14, 'max_depth': 26, 'n_estimators': 159}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:23:43,693] Trial 91 finished with value: 0.7780645814353679 and parameters: {'learning_rate': 0.05467113740213392, 'min_child_samples': 23, 'max_depth': 26, 'n_estimators': 278}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:23:52,316] Trial 92 finished with value: 0.7795323413300942 and parameters: {'learning_rate': 0.06675401684878346, 'min_child_samples': 10, 'max_depth': 28, 'n_estimators': 239}. Best is trial 78 with value: 0.7808482639943314.\n",
      "[I 2025-06-07 12:24:00,490] Trial 93 finished with value: 0.7809494888146573 and parameters: {'learning_rate': 0.06655420653782271, 'min_child_samples': 13, 'max_depth': 28, 'n_estimators': 241}. Best is trial 93 with value: 0.7809494888146573.\n",
      "[I 2025-06-07 12:24:08,104] Trial 94 finished with value: 0.7749772244154266 and parameters: {'learning_rate': 0.060825668908771016, 'min_child_samples': 29, 'max_depth': 27, 'n_estimators': 221}. Best is trial 93 with value: 0.7809494888146573.\n",
      "[I 2025-06-07 12:24:15,456] Trial 95 finished with value: 0.778216418665857 and parameters: {'learning_rate': 0.038407600639108204, 'min_child_samples': 14, 'max_depth': 29, 'n_estimators': 206}. Best is trial 93 with value: 0.7809494888146573.\n",
      "[I 2025-06-07 12:24:23,551] Trial 96 finished with value: 0.7776090697439012 and parameters: {'learning_rate': 0.06525708358298372, 'min_child_samples': 22, 'max_depth': 30, 'n_estimators': 247}. Best is trial 93 with value: 0.7809494888146573.\n",
      "[I 2025-06-07 12:24:30,407] Trial 97 finished with value: 0.7802915274825386 and parameters: {'learning_rate': 0.04938061640359837, 'min_child_samples': 14, 'max_depth': 28, 'n_estimators': 189}. Best is trial 93 with value: 0.7809494888146573.\n",
      "[I 2025-06-07 12:24:37,081] Trial 98 finished with value: 0.7818605121975909 and parameters: {'learning_rate': 0.04812659274087647, 'min_child_samples': 14, 'max_depth': 28, 'n_estimators': 193}. Best is trial 98 with value: 0.7818605121975909.\n",
      "[I 2025-06-07 12:24:42,597] Trial 99 finished with value: 0.6817997773053953 and parameters: {'learning_rate': 0.04973150161903763, 'min_child_samples': 133, 'max_depth': 27, 'n_estimators': 187}. Best is trial 98 with value: 0.7818605121975909.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa6b4820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.04812659274087647,\n",
       " 'min_child_samples': 14,\n",
       " 'max_depth': 28,\n",
       " 'n_estimators': 193}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e6f2c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=3,\n",
    "    metric=\"multi_logloss\",\n",
    "    # is_unbalance=True,\n",
    "    # class_weight=\"balanced\",\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    min_child_samples=best_params[\"min_child_samples\"],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd5dfc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9875\n",
      "[LightGBM] [Info] Number of data points in the train set: 19758, number of used features: 1009\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.04812659274087647, max_depth=28,\n",
       "               metric=&#x27;multi_logloss&#x27;, min_child_samples=14, n_estimators=193,\n",
       "               n_jobs=-1, num_class=3, objective=&#x27;multiclass&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.04812659274087647, max_depth=28,\n",
       "               metric=&#x27;multi_logloss&#x27;, min_child_samples=14, n_estimators=193,\n",
       "               n_jobs=-1, num_class=3, objective=&#x27;multiclass&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.04812659274087647, max_depth=28,\n",
       "               metric='multi_logloss', min_child_samples=14, n_estimators=193,\n",
       "               n_jobs=-1, num_class=3, objective='multiclass', random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a19610f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8358639538414819"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = best_model.predict(X_train_combined)\n",
    "accuracy_train = accuracy_score(\n",
    "    y_true=y_train,\n",
    "    y_pred=y_train_pred\n",
    ")\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d61c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      6586\n",
      "           1       0.89      0.79      0.84      6586\n",
      "           2       0.84      0.77      0.80      6586\n",
      "\n",
      "    accuracy                           0.84     19758\n",
      "   macro avg       0.84      0.84      0.83     19758\n",
      "weighted avg       0.84      0.84      0.83     19758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_train = classification_report(\n",
    "    y_true=y_train,\n",
    "    y_pred=y_train_pred\n",
    ")\n",
    "print(classification_report_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb998e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792952745151598"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_test_pred = best_model.predict(X_test_combined)\n",
    "accuracy_test = accuracy_score(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_test_pred\n",
    ")\n",
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b6c95ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.85      2530\n",
      "           1       0.89      0.73      0.81      3145\n",
      "           2       0.64      0.71      0.67      1647\n",
      "\n",
      "    accuracy                           0.79      7322\n",
      "   macro avg       0.78      0.79      0.78      7322\n",
      "weighted avg       0.80      0.79      0.79      7322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_test = classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_test_pred\n",
    ")\n",
    "print(classification_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f6189ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log results to MLFlow\n",
    "def log_to_mlflow(\n",
    "    model_name,\n",
    "    improvement_technique,\n",
    "    model,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    best_params\n",
    "):\n",
    "    with mlflow.start_run():\n",
    "        # Tags\n",
    "        mlflow.set_tag(\n",
    "            \"mlflow.runName\", f\"{model_name}_{improvement_technique}\"\n",
    "        )\n",
    "        mlflow.set_tag(\"experiment_type\", \"Improving LightGBM\")\n",
    "        \n",
    "        # Logging improvement technique as a parameter\n",
    "        mlflow.log_param(\"improvement_technique\", improvement_technique)\n",
    "        \n",
    "        # Initializing and training the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Making predictions on the test set and logging metrics\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Logging cross-val accuracy\n",
    "        scores = cross_val_score(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=3,\n",
    "            scoring=\"accuracy\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        mlflow.log_metric(\"cross_val_accuracy\", scores.mean())\n",
    "        \n",
    "        # Logging accuracy\n",
    "        accuracy = accuracy_score(\n",
    "            y_true=y_test,\n",
    "            y_pred=y_pred\n",
    "        )\n",
    "        mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "        \n",
    "        # Logging classification report metrics\n",
    "        classification_rep = classification_report(\n",
    "            y_true=y_test,\n",
    "            y_pred=y_pred,\n",
    "            output_dict=True\n",
    "        )\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}: {metric} - test\", value)\n",
    "        \n",
    "        # Logging the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "        \n",
    "        # Logging the best parameters\n",
    "        mlflow.log_params(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d03cd46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9875\n",
      "[LightGBM] [Info] Number of data points in the train set: 19758, number of used features: 1009\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 12:41:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run LightGBM_custom_features at: https://dagshub.com/SushrutGaikwad/youtube-comments-analyzer.mlflow/#/experiments/7/runs/d5060cc82d0d462c86f7578b55196087\n",
      "ðŸ§ª View experiment at: https://dagshub.com/SushrutGaikwad/youtube-comments-analyzer.mlflow/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "log_to_mlflow(\n",
    "    model_name=\"LightGBM\",\n",
    "    improvement_technique=\"custom_features\",\n",
    "    model=best_model,\n",
    "    X_train=X_train_combined,\n",
    "    X_test=X_test_combined,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    best_params=best_params\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
